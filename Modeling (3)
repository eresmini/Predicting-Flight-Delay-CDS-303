#%%

# -*- coding: utf-8 -*-
"""
Created on Sun Oct 10 20:13:04 2021
@author: Emma
"""

import pandas as pd
import numpy as np
import datetime
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

#%%

df3 = pd.read_csv('cleaned_dataframe.csv', index_col=0)

# converting most int64 types back to int32 (they revert when reading in the csv)
df3 = dfa.astype({
    'DEP_DELAY': int,
    'TAXI_OUT' : int,
    'WHEELS_OFF' : int,
    'WHEELS_ON' : int,
    'TAXI_IN' : int,
    'ARR_DELAY' : int,
    'SCHEDULED_ELAPSED_TIME' : int,
    'ACTUAL_ELAPSED_TIME' : int,
    'AIR_TIME' : int,
    'DISTANCE' : int
            })

#%%

# make sure we still have no missing values
missing_df1 = df3.isnull().sum(axis=0).reset_index()
missing_df1.columns = ['variable', 'missing values']
missing_df1['filling factor (%)']=(df3.shape[0]-missing_df1['missing values'])/df3.shape[0]*100
missing_df1.sort_values('filling factor (%)').reset_index(drop = True)


#%%

delays1 = df3.FLIGHT_STATUS1.value_counts(normalize=True)
delays2 = df3.FLIGHT_STATUS2.value_counts(normalize=True)

#%%

# numerical attributes

df3.hist(figsize = [15, 15],bins=9) 
plt.show()

#%%

#categorical attributes

fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(16,14), sharey=True)

categoricals = ['CARRIER','ORIGIN','DEST',
                'Year','Month','WEEKDAY']

for col, ax in zip(categoricals, axes.flatten()):
    (df3.groupby(col).sum()['FLIGHT_STATUS1'].sort_values().plot.bar(ax=ax))
    
    ax.set_title(col)
    
fig.tight_layout()


#%%

### MODELING HERE WE GOOOOO
# Datacamp logistic regression: https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python

# checking for multicollinearity

plt.figure(figsize=(20,14))
ax = sns.heatmap(df3.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Heat Map)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()

#%%

## MODEL 1 - classification - on time or delayed
# By DoT definition, any flight is delayed if it departs more than 15 minutes past schedule

feature_cols = ['CARRIER_NAME', 'ORIGIN', 'WEEKDAY', 'Month','Year']
df3.dropna()
X = df3[feature_cols]
y = df3.classifier_1

#%%

# creating instance of labelencoder
labelencoder = LabelEncoder()
# Assigning numerical values and storing in another column
X['CARRIER_Cat'] = labelencoder.fit_transform(X[['CARRIER_NAME']])
X['ORIGIN_Cat'] = labelencoder.fit_transform(X[['ORIGIN']])
X = X.drop(columns=['CARRIER_NAME','ORIGIN'])

#%%

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)

#%%

# instantiate the model (using the default parameters)
logreg = LogisticRegression(max_iter=1000)

# fit the model with data
fit = logreg.fit(X_train,y_train)

#logreg.fit(X,y)

y_pred=fit.predict(X_test)
#y_pred=logreg.predict(X)

#%%


cnf_matrix = metrics.confusion_matrix(y_test, y_pred)

print(cnf_matrix)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print("Precision:",metrics.precision_score(y_test, y_pred))
print("Recall:",metrics.recall_score(y_test, y_pred))

#%%

# ROC Curve

y_pred_proba = logreg.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
auc = metrics.roc_auc_score(y_test, y_pred_proba)
plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
plt.legend(loc=4)
plt.show()

#%%

## RANDOM FOREST

from sklearn import metrics, linear_model
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, RepeatedStratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier, RandomForestClassifier
from scipy.optimize import curve_fit
from sklearn.svm import SVC
from random import sample

import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import StandardScaler, LabelBinarizer

import statsmodels.formula.api as smf
import statsmodels.stats.api as sms
from statsmodels.formula.api import ols
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
import scipy.stats as stats

#%%

# see how classifiers are balanced

def scaling_check1(data):
    
    case_count = df3['FLIGHT_STATUS1'].value_counts() # 'data' is our input which will be any of the 3 dataframes created
    print('Legend:')
    print(case_count)
    
    plt.figure(figsize=(10,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.rcParams["figure.facecolor"] = "lightblue"
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)), ['ON TIME(0)', 'DELAYED(1)'])
    plt.show()

scaling_check1(df3)

def scaling_check2(data):
    
    case_count = df3['FLIGHT_STATUS2'].value_counts() # 'data' is our input which will be any of the 3 dataframes created
    print('Legend:')
    print(case_count)
    
    plt.figure(figsize=(10,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.rcParams["figure.facecolor"] = "lightblue"
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)), ['On Time(0)', 'Minor Delay(1)', 'Medium Delay(2)', 'Large Delay(3)', 'Gross Delay(4)'])
    plt.show()

scaling_check2(df3)

#%%

# two-part classifier

weights = df3.FLIGHT_STATUS1.value_counts()
count_0 = weights[0]
count_1 = weights[1]

initial_bias = np.log([count_1/count_0])
initial_bias

weight_for_0 = (1/count_0)*(count_0 + count_1)/2.0
weight_for_1 = (1/count_1)*(count_0 + count_1)/2.0

class_weight1 = {0: weight_for_0, 1: weight_for_1}

print('Weight for class 0: {:.2f}'.format(weight_for_0))
print('Weight for class 1: {:.2f}'.format(weight_for_1))

#%%

dfm = df3
OP_CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)

dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'Month', 'WEEKDAY', 'Year','Day'], axis=1)
dfm = pd.concat([dfm, OP_CARRIER_dummies, ORIGIN_dummies, DEST_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies, WEEKDAY_dummies], axis=1)


#%%

dfm = df3

# Get one hot encoding of categorical columns
one_hot = pd.get_dummies(dfm[['CARRIER','ORIGIN','DEST','WEEKDAY']])
# Drop column that are now encoded
dfm = dfm.drop(['CARRIER','ORIGIN','DEST','WEEKDAY'],axis = 1)
# Join the encoded df
dfm = dfm.join(one_hot)

#%%

# Create features (X) and labels (y)
y = dfm['FLIGHT_STATUS1']
X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY'], axis=1)

X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.25, random_state=42)
forest = RandomForestClassifier(n_estimators=100, max_depth=5, class_weight="balanced")
forest.fit(X_train, y_train)

forest.score(X_train, y_train)
forest.score(X_test, y_test)
