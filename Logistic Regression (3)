# -*- coding: utf-8 -*-
"""
Created on Sat Nov 27 12:08:18 2021

@author: eresmini
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.utils import resample

#%%

df3 = pd.read_csv('cleaned_dataframe.csv', index_col=0)

#%%

# converting most int64 types back to int32 (they revert when reading in the csv)
df3 = df3.astype({
    'DEP_DELAY': int,
    'TAXI_OUT' : int,
    'WHEELS_OFF' : int,
    'WHEELS_ON' : int,
    'TAXI_IN' : int,
    'ARR_DELAY' : int,
    'SCHEDULED_ELAPSED_TIME' : int,
    'ACTUAL_ELAPSED_TIME' : int,
    'AIR_TIME' : int,
    'DISTANCE' : int,
    'Year' : int,
    'Month' : int,
    'Day' : int,
    'WEEKDAY' : int,
    'FLIGHT_STATUS1' : int,
    'FLIGHT_STATUS2' : int
            })

#%%

info = df3.info()

#%%

# make sure we still have no missing values
missing_df1 = df3.isnull().sum(axis=0).reset_index()
missing_df1.columns = ['variable', 'missing values']
missing_df1['filling factor (%)']=(df3.shape[0]-missing_df1['missing values'])/df3.shape[0]*100
missing_df1.sort_values('filling factor (%)').reset_index(drop = True)


#%%

delays1 = df3.FLIGHT_STATUS1.value_counts(normalize=True)
delays2 = df3.FLIGHT_STATUS2.value_counts(normalize=True)

#%%

# checking for multicollinearity ( heat map )
X = df3.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
plt.figure(figsize=(26,18))
ax = sns.heatmap(X.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Numerical Values)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()

# removing columns that show multicollinearity
variables_to_remove = ['DISTANCE','AIR_TIME','WHEELS_ON','WHEELS_OFF',
                       'SCHEDULED_ELAPSED_TIME',
                       'SCHEDULED_DEP', 'SCHEDULED_ARR']
df3.drop(variables_to_remove, axis=1, inplace=True)

# checking for multicollinearity again ( heat map )
X = df3.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
plt.figure(figsize=(26,18))
ax = sns.heatmap(X.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Numerical Values)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()

#%%

def scaling_check1(data):
    
    case_count = data['FLIGHT_STATUS1'].value_counts()
    print('Legend:')
    print(case_count)
    
    plt.figure(figsize=(10,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.legend()
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)), ['On Time(0)', 'Delayed(1)'])
    plt.show()

scaling_check1(df3)

def scaling_check2(data):
    
    case_count = data['FLIGHT_STATUS2'].value_counts()
    print('Legend:')
    print(case_count)
    plt.figure(figsize=(10,6))
    sns.barplot(x=case_count.index, y=case_count.values)    
    plt.legend()
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)),
               ['On Time(0)', 'Minor Delay(1)', 'Medium Delay(2)', 'Large Delay(3)', 'Gross Delay(4)'], rotation=20)
    plt.show()

scaling_check2(df3)

#%%

# UPSAMPLING TO BALANCE CLASSES - FLIGHT_STATUS1

# Separate majority and minority classes
df_majority = df3[df3.FLIGHT_STATUS1==0]
df_minority = df3[df3.FLIGHT_STATUS1==1]
 
# Upsample minority class
df_minority_upsampled = resample(df_minority, replace=True, n_samples=8081425, random_state=123)
 
# Combine majority class with upsampled minority class
df1_upsampled = pd.concat([df_majority, df_minority_upsampled])
 
# Display new class counts
df1_upsampled.FLIGHT_STATUS1.value_counts()

# plot
scaling_check1(df1_upsampled)

#%%

# UPSAMPLING TO BALANCE CLASSES - FLIGHT_STATUS2

# Separate majority and minority classes
df2_0 = df3[df3.FLIGHT_STATUS2==0]
df2_1 = df3[df3.FLIGHT_STATUS2==1]
df2_2 = df3[df3.FLIGHT_STATUS2==2]
df2_3 = df3[df3.FLIGHT_STATUS2==3]
df2_4 = df3[df3.FLIGHT_STATUS2==4]
 
# Upsample minority class
df2_1_upsampled = resample(df2_1, replace=True, n_samples=8081425, random_state=123)
df2_2_upsampled = resample(df2_2, replace=True, n_samples=8081425, random_state=123)
df2_3_upsampled = resample(df2_3, replace=True, n_samples=8081425, random_state=123)
df2_4_upsampled = resample(df2_4, replace=True, n_samples=8081425, random_state=123)

# Combine majority class with upsampled minority class
df2_upsampled = pd.concat([df2_0, df2_1_upsampled, df2_2_upsampled, df2_3_upsampled, df2_4_upsampled])
 
# Display new class counts
df2_upsampled.FLIGHT_STATUS2.value_counts()

# plot
scaling_check2(df2_upsampled)

#%%

# Binary classification
# analyzes one airport
# will ask for user input: "Choose a carrier"

def LogisticRegression1(df):
    
    global dfm
    dfm = df
    
    # User input: Choose an airline
    carrier = input('Choose a carrier: ')
    dfm = dfm[dfm['CARRIER'] == carrier]
    if dfm.empty:
        print('No flights match your criteria.')
        return None
    
    # Create dummy variables
    CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
    ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
    DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
    IATA_dummies = pd.get_dummies(dfm['IATA'], prefix='IATA', drop_first=True)
    YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
    MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
    DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
    WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)

    # replace necessary columns in dataframe with dummy variables
    dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'IATA', 'Year', 'Month', 'Day', 'WEEKDAY'], axis=1)
    dfm = pd.concat([dfm, CARRIER_dummies, ORIGIN_dummies, DEST_dummies,
                     IATA_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies,
                     WEEKDAY_dummies], axis=1)

    # Create features (X) and labels (y)
    y = dfm['FLIGHT_STATUS1']
    X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
    
    # split into testing and training data
    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)
    
    # instantiate the model
    logreg = LogisticRegression(max_iter=200, class_weight="balanced")
    
    # fit the model with data
    fit = logreg.fit(X_train,y_train)

    #
    y_pred=fit.predict(X_test)
    
    # metrics results
    print("\nAccuracy for Logistic Regression: {:.6} %".format(accuracy_score(y_test,y_pred) * 100))
    print("\nPrecision for Logistic Regression: {:.6} %".format(metrics.precision_score(y_test, y_pred) * 100))
    print("\nRecall for Logistic Regression: {:.6} %".format(metrics.recall_score(y_test, y_pred) * 100))

    # confusion matrix plot
    cnf_matrix = metrics.confusion_matrix(y_test, y_pred)

    class_names=[0,1] # name  of classes
    fig, ax = plt.subplots()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names)
    plt.yticks(tick_marks, class_names)
    # create heatmap
    sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
    ax.xaxis.set_label_position("top")
    plt.tight_layout()
    plt.title('Confusion matrix', y=1.1)
    plt.ylabel('Actual label')
    plt.xlabel('Predicted label')


    # ROC Curve
    plt.figure(0) # Here's the part I need
    y_pred_proba = logreg.predict_proba(X_test)[::,1]
    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
    auc = metrics.roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr,tpr,label="data 1, auc="+str(auc))
    plt.legend(loc=4)
    plt.show()    

LogisticRegression1(df1_upsampled)

#%%

# 5-Part Classifier
# analyzes one airport
# will ask for user input: "Choose a carrier"

def LogisticRegression2(df):
    
    global dfm
    dfm = df
    
    # User input: Choose an airline
    carrier = input('Choose a carrier: ')
    dfm = dfm[dfm['CARRIER'] == carrier]
    if dfm.empty:
        print('No flights match your criteria.')
        return None
    
    # Create dummy variables
    CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
    ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
    DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
    IATA_dummies = pd.get_dummies(dfm['IATA'], prefix='IATA', drop_first=True)
    YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
    MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
    DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
    WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)

    # replace necessary columns in dataframe with dummy variables
    dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'IATA', 'Year', 'Month', 'Day', 'WEEKDAY'], axis=1)
    dfm = pd.concat([dfm, CARRIER_dummies, ORIGIN_dummies, DEST_dummies,
                     IATA_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies,
                     WEEKDAY_dummies], axis=1)

    # Create features (X) and labels (y)
    y = dfm['FLIGHT_STATUS2']
    X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
    
    # split into testing and training data
    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)
    
    # instantiate the model
    logreg = LogisticRegression(max_iter=2000, class_weight='balanced', 
                                multi_class='multinomial',n_jobs=-1)
    
    # fit the model with data
    fit = logreg.fit(X_train,y_train)

    #
    y_pred=fit.predict(X_test)
    
    # metrics results
    print("\nAccuracy for Logistic Regression: {:.6} %".format(accuracy_score(y_test,y_pred) * 100))
    print("\nPrecision for Logistic Regression: {:.6} %".format(metrics.precision_score(y_test, y_pred, average='weighted') * 100))
    print("\nRecall for Logistic Regression: {:.6} %".format(metrics.recall_score(y_test, y_pred, average='weighted') * 100))
    
    
    # plot confusion matrix
    fig, ax = plt.subplots(figsize=(10, 10))
    plot_confusion_matrix(fit, X, y, ax=ax)
    plt.show()

LogisticRegression2(df2_upsampled)
