#%%

# -*- coding: utf-8 -*-
"""
Created on Sun Oct 10 20:13:04 2021
@author: Emma
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score, plot_confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample

#%%

df3 = pd.read_csv('cleaned_dataframe.csv', index_col=0)

# converting most int64 types back to int32 (they revert when reading in the csv)
df3 = dfa.astype({
    'DEP_DELAY': int,
    'TAXI_OUT' : int,
    'WHEELS_OFF' : int,
    'WHEELS_ON' : int,
    'TAXI_IN' : int,
    'ARR_DELAY' : int,
    'SCHEDULED_ELAPSED_TIME' : int,
    'ACTUAL_ELAPSED_TIME' : int,
    'AIR_TIME' : int,
    'DISTANCE' : int
            })


#%%

# info on the dataframe - data type, memory storage, etc.
info = df3.info()

#%%

# make sure we still have no missing values
missing_df1 = df3.isnull().sum(axis=0).reset_index()
missing_df1.columns = ['variable', 'missing values']
missing_df1['filling factor (%)']=(df3.shape[0]-missing_df1['missing values'])/df3.shape[0]*100
missing_df1.sort_values('filling factor (%)').reset_index(drop = True)


#%%

delays1 = df3.FLIGHT_STATUS1.value_counts(normalize=True)
delays2 = df3.FLIGHT_STATUS2.value_counts(normalize=True)


#%%

# checking for multicollinearity ( heat map )
X = df3.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
plt.figure(figsize=(26,18))
ax = sns.heatmap(X.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Numerical Values)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()

# removing columns that show multicollinearity
variables_to_remove = ['DISTANCE','AIR_TIME','WHEELS_ON','WHEELS_OFF',
                       'SCHEDULED_ELAPSED_TIME',
                       'SCHEDULED_DEP', 'SCHEDULED_ARR']
df3.drop(variables_to_remove, axis=1, inplace=True)

# checking for multicollinearity again ( heat map )
X = df3.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
plt.figure(figsize=(26,18))
ax = sns.heatmap(X.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Numerical Values)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()


#%%

# see how classifiers are balanced

def scaling_check1(data):
    
    case_count = data['FLIGHT_STATUS1'].value_counts() # 'data' is our input which will be any of the 3 dataframes created
    print('Legend:')
    print(case_count)
    
    plt.figure(figsize=(10,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.rcParams["figure.facecolor"] = "lightblue"
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)), ['ON TIME(0)', 'DELAYED(1)'])
    plt.show()

scaling_check1(df3)

def scaling_check2(data):
    
    case_count = data['FLIGHT_STATUS2'].value_counts() # 'data' is our input which will be any of the 3 dataframes created
    print('Legend:')
    print(case_count)
    
    plt.figure(figsize=(10,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.rcParams["figure.facecolor"] = "lightblue"
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)), ['On Time(0)', 'Minor Delay(1)', 'Medium Delay(2)', 'Large Delay(3)', 'Gross Delay(4)'])
    plt.show()

scaling_check2(df3)

#%%

# UPSAMPLING TO BALANCE CLASSES
# FLIGHT_STATUS1

# Separate majority and minority classes
df_majority = df3[df3.FLIGHT_STATUS1==0]
df_minority = df3[df3.FLIGHT_STATUS1==1]
 
# Upsample minority class
df_minority_upsampled = resample(df_minority, replace=True, n_samples=8081425, random_state=123)
 
# Combine majority class with upsampled minority class
df1_upsampled = pd.concat([df_majority, df_minority_upsampled])
 
# Display new class counts
df1_upsampled.FLIGHT_STATUS1.value_counts()

# plot
scaling_check1(df1_upsampled)

# -------------------------------------

# UPSAMPLING TO BALANCE CLASSES
# FLIGHT_STATUS2

# Separate majority and minority classes
df2_0 = df3[df3.FLIGHT_STATUS2==0]
df2_1 = df3[df3.FLIGHT_STATUS2==1]
df2_2 = df3[df3.FLIGHT_STATUS2==2]
df2_3 = df3[df3.FLIGHT_STATUS2==3]
df2_4 = df3[df3.FLIGHT_STATUS2==4]
 
# Upsample minority class
df2_1_upsampled = resample(df2_1, replace=True, n_samples=8081425, random_state=123)
df2_2_upsampled = resample(df2_2, replace=True, n_samples=8081425, random_state=123)
df2_3_upsampled = resample(df2_3, replace=True, n_samples=8081425, random_state=123)
df2_4_upsampled = resample(df2_4, replace=True, n_samples=8081425, random_state=123)

# Combine majority class with upsampled minority class
df2_upsampled = pd.concat([df2_0, df2_1_upsampled, df2_2_upsampled, df2_3_upsampled, df2_4_upsampled])
 
# Display new class counts
df2_upsampled.FLIGHT_STATUS2.value_counts()

# plot
scaling_check2(df2_upsampled)

#%% ---------------------------------------------------------------------------

# Binary classification model
# analyzes one airport
# will ask for user input: "Choose a carrier"

def RandomForest1(df):
    
    global dfm
    dfm = df

    # User input: Choose an airline
    carrier = input('Choose a carrier: ')
    dfm = dfm[dfm['CARRIER'] == carrier]
    if dfm.empty:
        print('No flights match your criteria.')
        return None

    CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
    ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
    DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
    IATA_dummies = pd.get_dummies(dfm['IATA'], prefix='IATA', drop_first=True)
    YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
    MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
    DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
    WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)
    
    dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'IATA', 'Year', 'Month', 'Day', 'WEEKDAY'], axis=1)
    dfm = pd.concat([dfm, CARRIER_dummies, ORIGIN_dummies, DEST_dummies, IATA_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies, WEEKDAY_dummies], axis=1)

    # Create features (X) and labels (y)
    y = dfm['FLIGHT_STATUS1']
    X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY'], axis=1)
    
    X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.25, random_state=42)
    forest = RandomForestClassifier(n_estimators=100, max_depth=5, class_weight="balanced")
    fit = forest.fit(X_train, y_train)

    pred_rf = fit.predict(X_test)
    
    plot_confusion_matrix(fit, X, y, cmap='plasma')
    plt.show()
    
    # ROC Curve
    plt.figure(0)
    y_pred_proba = forest.predict_proba(X_test)[::,1]
    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
    auc = metrics.roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr,tpr,label="auc="+str(auc))
    plt.legend(loc=4)
    plt.show()

    print("Testing Accuracy for RandomForest Classifier: {:.6} %".format(accuracy_score(y_test, pred_rf) * 100))

RandomForest1(df3)

#%% ---------------------------------------------------------------------------

# multiclassification model
# analyzes one airport
# will ask for user input: "Choose a carrier"

def RandomForest2(df):
    
    global dfm
    dfm = df

    # User input: Choose an airline
    carrier = input('Choose a carrier: ')
    dfm = dfm[dfm['CARRIER'] == carrier]
    if dfm.empty:
        print('No flights match your criteria.')
        return None

    CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
    ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
    DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
    IATA_dummies = pd.get_dummies(dfm['IATA'], prefix='IATA', drop_first=True)
    YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
    MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
    DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
    WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)
    
    dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'IATA', 'Year', 'Month', 'Day', 'WEEKDAY'], axis=1)
    dfm = pd.concat([dfm, CARRIER_dummies, ORIGIN_dummies, DEST_dummies, IATA_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies, WEEKDAY_dummies], axis=1)

    # Create features (X) and labels (y)
    y = dfm['FLIGHT_STATUS2']
    X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY'], axis=1)
    
    X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.25, random_state=42)
    forest = RandomForestClassifier(n_estimators=200, max_depth=20,
                                    class_weight="balanced", n_jobs=-1)
    fit = forest.fit(X_train, y_train)
    y_pred = fit.predict(X_test)
    
    # plot confusion matrix
    fig, ax = plt.subplots(figsize=(10, 10))
    plot_confusion_matrix(fit, X, y, ax=ax, cmap='plasma')
    plt.show()
    
    # metrics results
    print("\nAccuracy for Random Forest Classifier: {:.6} %".format(accuracy_score(y_test, y_pred) * 100))
    print("\nPrecision for Random Forest Classifier: {:.6} %".format(metrics.precision_score(y_test, y_pred, average='macro') * 100))
    print("\nRecall for Random Forest Classifier: {:.6} %".format(metrics.recall_score(y_test, y_pred, average='macro') * 100))

RandomForest2(df3)
