#%%

# -*- coding: utf-8 -*-
"""
Created on Sun Oct 10 20:13:04 2021
@author: Emma
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier

from sklearn.model_selection import StratifiedKFold
from cf_matrix import *
from sklearn.model_selection import cross_val_score

#%%

df3 = pd.read_csv('cleaned_dataframe.csv', index_col=0)

# converting most int64 types back to int32 (they revert when reading in the csv)
df3 = df3.astype({
    'DEP_DELAY': int,
    'TAXI_OUT' : int,
    'WHEELS_OFF' : int,
    'WHEELS_ON' : int,
    'TAXI_IN' : int,
    'ARR_DELAY' : int,
    'SCHEDULED_ELAPSED_TIME' : int,
    'ACTUAL_ELAPSED_TIME' : int,
    'AIR_TIME' : int,
    'DISTANCE' : int,
    'Year' : int,
    'Month' : int,
    'Day' : int,
    'WEEKDAY' : int,
    'FLIGHT_STATUS1' : int,
    'FLIGHT_STATUS2' : int
            })


#%%

# make sure we still have no missing values
missing_df1 = df3.isnull().sum(axis=0).reset_index()
missing_df1.columns = ['variable', 'missing values']
missing_df1['filling factor (%)']=(df3.shape[0]-missing_df1['missing values'])/df3.shape[0]*100
missing_df1.sort_values('filling factor (%)').reset_index(drop = True)

#%%

# checking for multicollinearity ( heat map )
X = df3.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
plt.figure(figsize=(26,18))
ax = sns.heatmap(X.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Numerical Values)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()

# removing columns that show multicollinearity
variables_to_remove = ['DISTANCE','AIR_TIME','WHEELS_ON','WHEELS_OFF',
                       'SCHEDULED_ELAPSED_TIME',
                       'SCHEDULED_DEP', 'SCHEDULED_ARR']
df3.drop(variables_to_remove, axis=1, inplace=True)

# checking for multicollinearity again ( heat map )
X = df3.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'DEP_DELAY', 'ARR_DELAY'], axis=1)
plt.figure(figsize=(26,18))
ax = sns.heatmap(X.corr(), cmap='viridis', center=0, annot=True)
bottom, top = ax.get_ylim()
plt.text(0,-0.6, "Variable Multicollinearity (Numerical Values)", fontsize = 30, color='Black', fontstyle='normal')
ax.set_ylim(bottom + 0.5, top - 0.5)
plt.yticks(rotation=0, fontsize=14)
plt.xticks(rotation=45, fontsize=14)
plt.show()

#%%

# see how classifiers are balanced

def scaling_check1(data):
    
    case_count = data['FLIGHT_STATUS1'].value_counts() # 'data' is our input which will be any of the 3 dataframes created
    print('Legend:')
    print(case_count)
    
    # barplot
    plt.figure(figsize=(6,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.legend()
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)), ['On Time(0)', 'Delayed(1)'])
    plt.show()

def scaling_check2(data):
    
    case_count = data['FLIGHT_STATUS2'].value_counts() # 'data' is our input which will be any of the 3 dataframes created
    print('Legend:')
    print(case_count)
    
    # bar plot
    plt.figure(figsize=(6,6))
    sns.barplot(x=case_count.index, y=case_count.values)
    plt.legend()
    plt.title('Data Distribution', fontsize=16)
    plt.xlabel('Flight Status', fontsize=12)
    plt.ylabel('Number of Flights', fontsize=12)
    plt.xticks(range(len(case_count.index)),
                ['On Time(0)', 'Minor Delay(1)', 'Medium Delay(2)', 'Large Delay(3)', 'Gross Delay(4)'], rotation=20)
    plt.show()
    
#%%

scaling_check1(df3)
scaling_check2(df3)

#%% ---------------------------------------------------------------------------

def RandomForest1(df):
    
    global dfm, delays1, y_pred
    dfm = df

    # User input: Choose an airline
    carrier = input('Choose a carrier: ')
    dfm = dfm[dfm['CARRIER'] == carrier]
    if dfm.empty:
        print('No flights match your criteria.')
        return None
    
    # "true" percentage of on-time/delayed flights
    delays1 = dfm.FLIGHT_STATUS1.value_counts(normalize=True)
    
    #create dummy variables
    CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
    ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
    DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
    IATA_dummies = pd.get_dummies(dfm['IATA'], prefix='IATA', drop_first=True)
    YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
    MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
    DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
    WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)
    
    # add dummy variables to dataframe
    dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'IATA',
                    'Year', 'Month', 'Day', 'WEEKDAY'], axis=1)
    dfm = pd.concat([dfm, CARRIER_dummies, ORIGIN_dummies, DEST_dummies,
                     IATA_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies,
                     WEEKDAY_dummies], axis=1)

    # Create features (X) and labels (y)
    y = dfm['FLIGHT_STATUS1']
    X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'ARR_DELAY'], axis=1)
    
    # stratified k-vold
    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)
    for train_index, test_index in skf.split(X, y):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    
    #X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.25, random_state=42)
        
    # random forest classifier model
    forest = RandomForestClassifier(n_estimators=400, max_depth=10,
                                    class_weight="balanced",
                                    max_features=None, criterion='gini',
                                    n_jobs=-1)
    
    fit = forest.fit(X_train, y_train)
    y_pred = fit.predict(X_test)

    # predictions
    ontime = (y_pred==0).sum()
    delayed = (y_pred==1).sum()
    total = len(y_pred)
    print("\nPREDICTIONS:")
    print("On-time flight: {:.6} %".format((ontime / total) * 100))
    print("Delayed flight: {:.6} %".format((delayed / total) * 100))
    
    # metrics results
    print("\nMODEL METRICS:")
    print("Accuracy: {:.6} %".format(accuracy_score(y_test, y_pred) * 100))
    print("Precision: {:.6} %".format(metrics.precision_score(y_test, y_pred, average='macro') * 100))
    print("Recall: {:.6} %".format(metrics.recall_score(y_test, y_pred, average='macro') * 100))
    
    # confusion matrix
    cf_matrix = metrics.confusion_matrix(y_test, y_pred)
    categories = ['On Time', 'Delayed']
    make_confusion_matrix(cf_matrix, 
                          categories=categories, 
                          cmap='plasma')
    
    # ROC Curve
    plt.figure(0)
    y_pred_proba = forest.predict_proba(X_test)[::,1]
    fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)
    auc = metrics.roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr,tpr,label="auc="+str(auc))
    plt.legend(loc=4)
    plt.show()
    
    # validation
    scores = cross_val_score(forest, X_train, y_train, cv=5)
    print('\nVALIDATION:')
    print("%0.2f accuracy with a standard deviation of %0.4f" % (scores.mean(), scores.std()))
        
RandomForest1(df3)
#%%

carriers = list(df3.CARRIER.unique())

for carrier in carriers:
    print(carrier)
    RandomForest1(df3, carrier)

#%% ---------------------------------------------------------------------------

def RandomForest2(df):
    
    global dfm, delays2
    dfm = df

    # User input: Choose an airline
    carrier = input('Choose a carrier: ')
    dfm = dfm[dfm['CARRIER'] == carrier]
    if dfm.empty:
        print('No flights match your criteria.')
        return None

    # "true" percentage of on-time/delayed flights
    delays2 = dfm.FLIGHT_STATUS2.value_counts(normalize=True) # "true" percentage
    
    # create dummy variables
    CARRIER_dummies = pd.get_dummies(dfm['CARRIER'], prefix='CARRIER', drop_first=True)
    ORIGIN_dummies = pd.get_dummies(dfm['ORIGIN'], prefix='ORIGIN', drop_first=True)
    DEST_dummies = pd.get_dummies(dfm['DEST'], prefix='DEST', drop_first=True)
    IATA_dummies = pd.get_dummies(dfm['IATA'], prefix='IATA', drop_first=True)
    YEAR_dummies = pd.get_dummies(dfm['Year'], prefix='Year', drop_first=True)
    MONTH_dummies = pd.get_dummies(dfm['Month'], prefix='Month', drop_first=True)
    DAY_dummies = pd.get_dummies(dfm['Day'], prefix='Day', drop_first=True)
    WEEKDAY_dummies = pd.get_dummies(dfm['WEEKDAY'], prefix='WEEKDAY', drop_first=True)
    
    # add dummy variables to dataframe
    dfm = dfm.drop(['CARRIER', 'ORIGIN', 'DEST', 'IATA', 'Year',
                    'Month', 'Day', 'WEEKDAY'], axis=1)
    dfm = pd.concat([dfm, CARRIER_dummies, ORIGIN_dummies, DEST_dummies,
                     IATA_dummies, YEAR_dummies, MONTH_dummies, DAY_dummies,
                     WEEKDAY_dummies], axis=1)

    # Create features (X) and labels (y)
    y = dfm['FLIGHT_STATUS2']
    X = dfm.drop(['FLIGHT_STATUS1', 'FLIGHT_STATUS2', 'ARR_DELAY'], axis=1)
    
    # stratified k-vold
    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)
    for train_index, test_index in skf.split(X, y):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    
    # X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.25, random_state=42)
    
    # random forest classifier model
    forest = RandomForestClassifier(n_estimators=200, max_depth=10,
                                    max_features=None, criterion='gini',
                                    class_weight='balanced',
                                     n_jobs=-1)
    fit = forest.fit(X_train, y_train)
    y_pred = fit.predict(X_test)
    
    # predictions
    ontime = (y_pred==0).sum()
    delay1 = (y_pred==1).sum()
    delay2 = (y_pred==2).sum()
    delay3 = (y_pred==3).sum()
    delay4 = (y_pred==4).sum()
    total = len(y_pred)
    print('\nPREDICTIONS:')
    print('No delay: {:.6} %'.format((ontime/total) * 100))
    print("15-30 mins delay: {:.6} %".format((delay1/total) * 100))
    print("30-60 mins delay: {:.6} %".format((delay2/total) * 100))
    print("60-90 mins delay: {:.6} %".format((delay3/total) * 100))
    print("90+ mins delay: {:.6} %".format((delay4/total) * 100))
    
    # confusion matrix
    cf_matrix = metrics.confusion_matrix(y_test, y_pred)
    categories = ['No Delay', '15-30min', '30-60min', '60-90min', '90+min']
    make_confusion_matrix(cf_matrix, categories=categories, cmap='plasma')
    
    # metrics results
    # average precision, recall
    print('\nMODEL METRICS:')
    print("Accuracy: {:.6} %".format(accuracy_score(y_test, y_pred) * 100))
    print("Precision: {:.6} %".format(metrics.precision_score(y_test, y_pred, average='macro') * 100))
    print("Recall: {:.6} %".format(metrics.recall_score(y_test, y_pred, average='macro') * 100))
    
    # validation
    scores = cross_val_score(forest, X, y, cv=5)
    print('\nVALIDATION:')
    print("%0.2f accuracy with a standard deviation of %0.4f" % (scores.mean(), scores.std()))

RandomForest2(df3)
